{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "358696ff",
   "metadata": {},
   "source": [
    "## Import Datasets and Packeges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3db9504a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandoc\n",
      "  Downloading pandoc-2.3.tar.gz (33 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting plumbum (from pandoc)\n",
      "  Downloading plumbum-1.8.3-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting ply (from pandoc)\n",
      "  Downloading ply-3.11-py2.py3-none-any.whl.metadata (844 bytes)\n",
      "Requirement already satisfied: pywin32 in c:\\python 311\\lib\\site-packages (from plumbum->pandoc) (305)\n",
      "Downloading plumbum-1.8.3-py3-none-any.whl (127 kB)\n",
      "   ---------------------------------------- 0.0/127.6 kB ? eta -:--:--\n",
      "   ------------ --------------------------- 41.0/127.6 kB 2.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 122.9/127.6 kB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- 127.6/127.6 kB 938.9 kB/s eta 0:00:00\n",
      "Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
      "   ---------------------------------------- 0.0/49.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 49.6/49.6 kB 1.3 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: pandoc\n",
      "  Building wheel for pandoc (pyproject.toml): started\n",
      "  Building wheel for pandoc (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pandoc: filename=pandoc-2.3-py3-none-any.whl size=33292 sha256=d18f0c68e879483d50f66900babbe2d480f41ffe9aa00cc6cd1d287e97927415\n",
      "  Stored in directory: c:\\users\\sarvadnya\\appdata\\local\\pip\\cache\\wheels\\1c\\a9\\c4\\6254542c4e8202d52fcd69798d2507aaad1f2a4bb60f2f0fea\n",
      "Successfully built pandoc\n",
      "Installing collected packages: ply, plumbum, pandoc\n",
      "Successfully installed pandoc-2.3 plumbum-1.8.3 ply-3.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: nb-black 1.0.7 has a non-standard dependency specifier black>='19.3'; python_version >= \"3.6\". pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of nb-black or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0e056557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "# Suppress specific warning\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "da93f8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set display options to show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Load all columns from the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"ML df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f083ebad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is already loaded with the necessary data\n",
    "X = df[['City', 'Team1', 'Team2', 'Venue', 'TossWinner', 'TossDecision','Team1BatAvg',\n",
    "       'Team2BatAvg', 'Team1BallAvg', 'Team2BallAvg']].copy()\n",
    "y = df['WinningTeam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3cb24958",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1207ab04",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cba7d496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding only categorical variables\n",
    "label_encoders = {}\n",
    "categorical_columns = ['City', 'Team1', 'Team2', 'Venue', 'TossWinner', 'TossDecision']\n",
    "\n",
    "# Encode categorical features\n",
    "for column in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    X[column] = le.fit_transform(X[column])\n",
    "    label_encoders[column] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b65f2a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding target variable\n",
    "le_y = LabelEncoder()\n",
    "y = le_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b64b7c",
   "metadata": {},
   "source": [
    "## Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ce38ad03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bc9ab3",
   "metadata": {},
   "source": [
    "## Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cc241ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "\n",
    "# K-Nearest Neighbors (KNN)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c94692",
   "metadata": {},
   "source": [
    "## Accuracy Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "52253e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Performance Metrics:\n",
      "Logistic Regression - Training Accuracy: 0.3544973544973545 Test Accuracy: 0.2894736842105263\n",
      "K-Nearest Neighbors - Training Accuracy: 0.49074074074074076 Test Accuracy: 0.2894736842105263\n",
      "Random Forest - Training Accuracy: 1.0 Test Accuracy: 0.49473684210526314\n",
      "Decision Tree - Training Accuracy: 1.0 Test Accuracy: 0.42105263157894735\n",
      "\n",
      "Classification Reports:\n",
      "Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.50      0.49        30\n",
      "           1       0.14      0.11      0.12        18\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.14      0.15      0.15        20\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.36      0.31      0.33        32\n",
      "           8       0.29      0.24      0.26        21\n",
      "           9       0.00      0.00      0.00         2\n",
      "          10       0.25      0.32      0.28        19\n",
      "          11       0.00      0.00      0.00         3\n",
      "          12       0.31      0.22      0.26        23\n",
      "          13       0.26      0.56      0.35        16\n",
      "\n",
      "    accuracy                           0.29       190\n",
      "   macro avg       0.17      0.19      0.17       190\n",
      "weighted avg       0.28      0.29      0.28       190\n",
      "\n",
      "K-Nearest Neighbors:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.50      0.48        30\n",
      "           1       0.14      0.17      0.15        18\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.26      0.45      0.33        20\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.54      0.41      0.46        32\n",
      "           8       0.17      0.14      0.15        21\n",
      "           9       0.00      0.00      0.00         2\n",
      "          10       0.25      0.21      0.23        19\n",
      "          11       0.00      0.00      0.00         3\n",
      "          12       0.19      0.13      0.15        23\n",
      "          13       0.25      0.31      0.28        16\n",
      "\n",
      "    accuracy                           0.29       190\n",
      "   macro avg       0.17      0.18      0.17       190\n",
      "weighted avg       0.29      0.29      0.29       190\n",
      "\n",
      "Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.80      0.70        30\n",
      "           1       0.44      0.44      0.44        18\n",
      "           2       0.50      1.00      0.67         1\n",
      "           3       1.00      0.25      0.40         4\n",
      "           4       0.53      0.50      0.51        20\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.62      0.47      0.54        32\n",
      "           8       0.17      0.10      0.12        21\n",
      "           9       0.00      0.00      0.00         2\n",
      "          10       0.55      0.58      0.56        19\n",
      "          11       0.00      0.00      0.00         3\n",
      "          12       0.48      0.48      0.48        23\n",
      "          13       0.35      0.69      0.47        16\n",
      "\n",
      "    accuracy                           0.49       190\n",
      "   macro avg       0.40      0.41      0.38       190\n",
      "weighted avg       0.48      0.49      0.48       190\n",
      "\n",
      "Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.53      0.58        30\n",
      "           1       0.21      0.17      0.19        18\n",
      "           2       0.50      1.00      0.67         1\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.35      0.55      0.43        20\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.71      0.53      0.61        32\n",
      "           8       0.30      0.29      0.29        21\n",
      "           9       0.00      0.00      0.00         2\n",
      "          10       0.31      0.42      0.36        19\n",
      "          11       0.25      0.33      0.29         3\n",
      "          12       0.53      0.43      0.48        23\n",
      "          13       0.35      0.44      0.39        16\n",
      "\n",
      "    accuracy                           0.42       190\n",
      "   macro avg       0.32      0.36      0.33       190\n",
      "weighted avg       0.44      0.42      0.42       190\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "log_reg_train_accuracy = accuracy_score(y_train, log_reg.predict(X_train))\n",
    "log_reg_test_accuracy = accuracy_score(y_test, y_pred_log_reg)\n",
    "log_reg_report = classification_report(y_test, y_pred_log_reg)\n",
    "\n",
    "# K-Nearest Neighbors (KNN)\n",
    "knn_train_accuracy = accuracy_score(y_train, knn.predict(X_train))\n",
    "knn_test_accuracy = accuracy_score(y_test, y_pred_knn)\n",
    "knn_report = classification_report(y_test, y_pred_knn)\n",
    "\n",
    "# Random Forest\n",
    "rf_train_accuracy = accuracy_score(y_train, rf.predict(X_train))\n",
    "rf_test_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "rf_report = classification_report(y_test, y_pred_rf)\n",
    "\n",
    "# Decision Tree\n",
    "dt_train_accuracy = accuracy_score(y_train, dt.predict(X_train))\n",
    "dt_test_accuracy = accuracy_score(y_test, y_pred_dt)\n",
    "dt_report = classification_report(y_test, y_pred_dt)\n",
    "\n",
    "# Print overall performance metrics\n",
    "print(\"Overall Performance Metrics:\")\n",
    "print(\"Logistic Regression - Training Accuracy:\", log_reg_train_accuracy, \"Test Accuracy:\", log_reg_test_accuracy)\n",
    "print(\"K-Nearest Neighbors - Training Accuracy:\", knn_train_accuracy, \"Test Accuracy:\", knn_test_accuracy)\n",
    "print(\"Random Forest - Training Accuracy:\", rf_train_accuracy, \"Test Accuracy:\", rf_test_accuracy)\n",
    "print(\"Decision Tree - Training Accuracy:\", dt_train_accuracy, \"Test Accuracy:\", dt_test_accuracy)\n",
    "print(\"\\nClassification Reports:\")\n",
    "print(\"Logistic Regression:\")\n",
    "print(log_reg_report)\n",
    "print(\"K-Nearest Neighbors:\")\n",
    "print(knn_report)\n",
    "print(\"Random Forest:\")\n",
    "print(rf_report)\n",
    "print(\"Decision Tree:\")\n",
    "print(dt_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5130042",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
